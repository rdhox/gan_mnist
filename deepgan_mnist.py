from keras.datasets.mnist import load_datafrom keras.utils import to_categoricalfrom keras.models import Sequentialfrom keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Reshape, LeakyReLU, Dropout, Conv2DTransposefrom keras.optimizers import SGD, Adamfrom keras.utils.vis_utils import plot_modelfrom numpy.random import randn, rand, randint, shufflefrom numpy import ones, zerosimport numpy as npfrom matplotlib import pyplotdef rand_bin_array(K, N, nb):    y = []    for i in range(nb):          arr = zeros(N)        arr[:K]  = 1        shuffle(arr)        y.append(arr)    return np.array(y)def load_dataset():    # load the images into memory    (trainX, _), (_, _) = load_data()    # reshape to have vector with one component as a value    trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))    X = prep_pixel(trainX)    return X    def prep_pixel(train):    train_norm = train.astype('float32')    # reduce the range [0, 255] to [0, 1]    train_norm = train_norm / 255    return train_normdef generate_real_sample(dataset, n_samples):    range_ix = randint(0, dataset.shape[0], n_samples)    X = dataset[range_ix]    y = ones((n_samples, 1))    return X, ydef get_discriminator(input_shape):    model = Sequential()    model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same', input_shape=input_shape))    model.add(LeakyReLU(alpha=0.2))    model.add(Dropout(0.4))    model.add(Conv2D(64, (3,3), strides=(2,2), padding='same'))    model.add(LeakyReLU(alpha=0.2))    model.add(Dropout(0.4))    model.add(Flatten())    model.add(Dense(1, activation='sigmoid'))    #compil    opt = Adam(lr=0.0002, beta_1=0.5)    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])    plot_model(model, to_file='discriminator_plot.png', show_shapes=True, show_layer_names=True)    return modeldef get_generator(latent_dim):    model = Sequential()    model.add(Dense(128*7*7, input_dim=latent_dim))    model.add(Reshape((7,7,128)))    # make image 14x14    model.add(Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same'))    model.add(LeakyReLU(alpha=0.2))    # make image 28x28    model.add(Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same'))    model.add(LeakyReLU(alpha=0.2))    model.add(Conv2D(1, (7, 7), activation='sigmoid', padding='same'))    plot_model(model, to_file='generator_plot.png', show_shapes=True, show_layer_names=True)    return model              def create_latent_points(latent_dim, n):    # create vector within range of value    input_x = randn(latent_dim*n)    input_x = input_x.reshape((n, latent_dim))    return input_x    def create_fake_sample(generator, latent_dim, n):    input_x = create_latent_points(latent_dim, n)    # print(input_x[0][0])    X = generator.predict(input_x)    # we mark all those input ad fake    y = zeros((n, 1))    return X, ydef get_gan(generator, discriminator):    model = Sequential()    # We freeze the discriminator to make him not update with the training of the gan    discriminator.trainable = False    model.add(generator)    model.add(discriminator)    model.compile(optimizer='adam', loss='binary_crossentropy')    plot_model(model, to_file='gan_plot.png', show_shapes=True, show_layer_names=True)    return modeldef train(trainX, generator, discriminator, gan, latent_dim, epochs=1000, n_batch=126, n_evals=200):    half_batch = int(n_batch/2)    for i in range(epochs):        # We train the discriminator        real_x, real_y = generate_real_sample(trainX, n_batch)        fake_x, fake_y = create_fake_sample(generator, latent_dim, half_batch)        discriminator.train_on_batch(real_x, real_y)        discriminator.train_on_batch(fake_x, fake_y)        # We train the gan        train_x = create_latent_points(latent_dim, n_batch)        # train_y = rand_bin_array(1, 10, n_batch)        train_y = ones((n_batch, 1))        gan.train_on_batch(train_x, train_y)        if (i+1) % n_evals == 0:            summarize_performance(trainX, generator, discriminator, latent_dim, i)        def summarize_performance(trainX, generator, discriminator, latent_dim, epoch):        x_sample, y_sample = create_fake_sample(generator, latent_dim, 100)        # Test the discriminator        real_x, real_y = generate_real_sample(trainX, 100)        fake_x, fake_y = create_fake_sample(generator, latent_dim, 100)        _, acc_real = discriminator.evaluate(real_x, real_y, verbose=0)        _, acc_fake = discriminator.evaluate(fake_x, fake_y, verbose=0)        print(epoch, acc_real, acc_fake)        for i in range(25):            pyplot.subplot(5, 5, i+1)            pyplot.axis('off')            pyplot.imshow(x_sample[i], cmap='gray_r')        pyplot.show()    def show_sample_data(trainX):    for i in range(25):        pyplot.subplot(5, 5, i+1)        pyplot.axis('off')        pyplot.imshow(trainX[i], cmap='gray_r')    pyplot.show()def run():    # load mnist set    trainX = load_dataset()    # show a sample of the dataset    show_sample_data(trainX)    # define parameters    input_shape = trainX[0].shape    latent_dim = 100    # create models    discriminator = get_discriminator(input_shape)    generator = get_generator(latent_dim)    gan = get_gan(generator, discriminator)    # let's train    train(        trainX,        generator,        discriminator,        gan,        latent_dim    )run()